import requests
import json
import os
import time
import random
from datetime import datetime, timedelta
from concurrent.futures import ThreadPoolExecutor, as_completed

# fih kolch tani
# l'utlisation daylo  when u run there's a menu you wil find it to choose what you wanna scrappe okay
# the menu is like this:
# last few hours
# last few days
# last few months
# all exploits (hadi all yscrappi kolch)
# exit
# so you can choose what you want to scrappe and the number of hours or days or months you want to scrappe
# and then you will find the result in the end of the execution
# and the result will be saved in a file called processed_vulnerabilities.json but i commented the line that save the result in the file
# so you can uncomment it if you want to save the result in the file
# and you can find the result in the console
# and i added a function that display the result in a good way


class ExploitDBScraper:
    def __init__(self, base_url="https://www.exploit-db.com/"):
        self.base_url = base_url
        self.headers = {
            "authority": "www.exploit-db.com",
            "accept": "application/json, text/javascript, */*; q=0.01",
            "x-requested-with": "XMLHttpRequest",
            "user-agent": "Mozilla/5.0 (X11; Linux x86_64)",
        }
        self.safe_retrieval_cap = 500
        self.data_dir = "./exploitdb_data"
        self.current_date = datetime.now()
        os.makedirs(self.data_dir, exist_ok=True)
        self.max_retries = 3

    def is_within_timeframe(self, date_str, time_value, time_unit):
        try:
            date = datetime.strptime(date_str, "%Y-%m-%d")
            time_delta = {
                "hours": timedelta(hours=time_value),
                "days": timedelta(days=time_value),
                "months": timedelta(days=time_value * 30),
            }.get(time_unit)
            if not time_delta:
                raise ValueError("Invalid time unit")
            return date >= self.current_date - time_delta
        except (ValueError, TypeError):
            return False

    def request_by_bounds(self, start, length):
        for attempt in range(self.max_retries):
            try:
                response = requests.get(
                    self.base_url,
                    headers=self.headers,
                    params={
                        "start": start,
                        "length": length,
                        "columns[0][data]": "id",
                        "columns[1][name]": "id",
                        "order[0][column]": "0",
                        "order[0][dir]": "asc",
                    },
                    timeout=10,
                )
                response.raise_for_status()
                return response.json()
            except requests.RequestException as e:
                print(f"Request error (attempt {attempt+1}/{self.max_retries}): {e}")
                time.sleep(random.uniform(1, 3))
        return None

    def process_exploit_data(self, page_exploits, time_value=0, time_unit=None):
        formatted_exploits = []

        for exploit in page_exploits:
            date_published = exploit.get("date_published", "")

            if (
                time_value
                and time_unit
                and not self.is_within_timeframe(date_published, time_value, time_unit)
            ):
                continue

            cve_code = None
            for code_entry in exploit.get("code", []):
                if code_entry.get("code_type") == "cve":
                    cve_code = code_entry.get("code")
                    break

            if cve_code:
                cve_id = f"CVE-{cve_code}"
            else:
                year = date_published.split("-")[0] if "-" in date_published else "N/A"
                cve_id = f"CVE-{year}-{exploit.get('id', 'N/A')}"

            exploit_data = {
                "CVE_ID": cve_id,
                "Titre": str(exploit.get("id", "N/A")),
                "Description": exploit.get("description", ["N/A"])[-1],
                "Date_Published": date_published,
                "Last_Modified": None,
                "Type": None,
                "type_id": None,
                "Platform": None,
                "platform_id": None,
                "Author": None,
                "Severity": None,
                "References": None,
                "CVSS": None,
                "Created": None,
                "Added": None,
                "Solutions": None,
                "verified": None,
                "application_path": None,
                "application_md5": None,
                "Base_Score": None,
                "Attack_Vector": None,
                "Attack_Complexity": None,
                "Privileges_Required": None,
                "User_Interaction": None,
                "Scope": None,
                "Exploitability_Score": None,
                "Impact_Score": None,
                "Confidentiality_Impact": None,
                "Integrity_Impact": None,
                "Availability_Impact": None,
                "Affected_Software": None,
                "tags": None,
                "screenshot_path": None,
                "screenshot_thumb_path": None,
            }
            formatted_exploits.append(exploit_data)

        if formatted_exploits:
            print(json.dumps(formatted_exploits, indent=2))
        return formatted_exploits

    def scrape_exploits(self, time_value=0, time_unit=None):
        initial_data = self.request_by_bounds(0, 10)
        if not initial_data:
            return []

        total_exploits = initial_data.get("recordsTotal", 0)

        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            for page in range(0, total_exploits, self.safe_retrieval_cap):
                future = executor.submit(
                    self.request_by_bounds, page, self.safe_retrieval_cap
                )
                futures.append(future)
                time.sleep(random.uniform(0.5, 1.5))

            all_exploits = []
            for future in as_completed(futures):
                result = future.result()
                if result:
                    exploits = self.process_exploit_data(
                        result["data"], time_value, time_unit
                    )
                    all_exploits.extend(exploits)

        return all_exploits


def get_user_choice():
    print("\n=== ExploitDB Scraper ===")
    print("1. Last few hours")
    print("2. Last few days")
    print("3. Last few months")
    print("4. All exploits")
    print("5. Exit")

    while True:
        try:
            choice = int(input("\nEnter your choice (1-5): "))
            if choice == 5:
                return None, None
            if choice == 4:
                return 0, None
            

            units = {1: "hours", 2: "days", 3: "months"}
            if choice in units:

                value = int(input(f"Enter the number of {units[choice]}: "))
                if value > 0:
                    return value, units[choice]
            print("Please enter a valid choice and positive number.")
        except ValueError:
            print("Invalid input. Please enter a number.")


def main():
    # while True:
    #     time_value, time_unit = get_user_choice()
    #     if time_value is None:
    #         break
    #     scraper = ExploitDBScraper()
    #     scraper.scrape_exploits(time_value, time_unit)
    #     if input("\nPerform another scrape? (y/n): ").lower() != "y":
    #         break
    scraper = ExploitDBScraper()
    res = scraper.scrape_exploits(12, "hours")
    print(len(res))


if __name__ == "__main__":
    main()